import json
import torch
from datetime import datetime
from typing import List, Dict, Any, Callable, Optional
from dataclasses import dataclass
from pathlib import Path

from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from langchain.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

from main_model import preprocess_transcript

# ===== Configuration =====
CACHE_DIR = "/workspace/hf_cache"
# BASE_MODEL_NAME = "Qwen/Qwen3-8B"
BASE_MODEL_NAME = "Qwen/Qwen2.5-1.5B-instruct"
# FT_MODEL_NAME = "CHOROROK/Qwen3_8B_meeting_agenda_task"
FT_MODEL_NAME = "CHOROROK/Qwen2.5_1.5B_meeting_agenda_task"
DB_PATH = "./faiss_db_merged"

PROMPT_DIR = Path(__file__).parent / "prompts"
SYSTEM_PROMPT = (PROMPT_DIR / "system.txt").read_text(encoding="utf-8").strip()
PROMPTS = {
    "summarizer": (PROMPT_DIR / "summarizer.txt").read_text(encoding="utf-8").strip(),
    "task_extractor": (PROMPT_DIR / "extract_tasks.txt").read_text(encoding="utf-8").strip(),
}


# ì±„íŒ… ë³´ë‚´ëŠ” ë©”ì‹œì§€ êµ¬ì¡°
@dataclass
class Message:
    role: str
    content: str
    tool_calls: Optional[List[Dict[str, Any]]] = None
    tool_call_id: Optional[str] = None
    name: Optional[str] = None


# ì •ì˜í•  íˆ´ ë‚´ë¶€ êµ¬ì¡°
@dataclass
class Tool:
    name: str
    description: str
    parameters: Dict[str, Any]
    function: Callable


class QwenLLMAgent:
    def __init__(
        self,
        model_id: str = BASE_MODEL_NAME,
        adapter_id: Optional[str] = FT_MODEL_NAME,
        device_map: str = "auto",
        torch_dtype: str = "auto",
        system_prompt: str = SYSTEM_PROMPT
    ):

        # Tokenizer ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_id,
            use_fast=False, 
            cache_dir=CACHE_DIR
        )

        # ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ: {model_id}")
        base_model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.bfloat16 if torch_dtype == "auto" else torch_dtype,
            device_map=device_map,
            cache_dir=CACHE_DIR
        )
        # ì–´ëŒ‘í„° ë¡œë“œ
        if adapter_id:
            print(f"ğŸ”§ ì–´ëŒ‘í„° ë¡œë“œ: {adapter_id}")
            self.model = PeftModel.from_pretrained(base_model, adapter_id)
        else:
            self.model = base_model

        self.messages: List[Message] = []
        self.system_prompt = system_prompt
        self.tools: Dict[str, Tool] = {}

        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n")

    # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    def set_system_prompt(self, system_prompt):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ê¸°ì¡´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        self.system_prompt = system_prompt
        user_messages = [m for m in self.messages if m.role != 'system']
        self.messages = user_messages

    # ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  íˆ´ ë“±ë¡
    def register_tool(self, name: str, description: str, parameters: Dict[str, Any], function: Callable):
        """íˆ´ì„ ë“±ë¡í•©ë‹ˆë‹¤."""
        tool = Tool(
            name=name,
            description=description,
            parameters=parameters,
            function=function
        )
        self.tools[name] = tool
        print(f"âœ… Registered tool: {name}")

    # í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•  íˆ´ ì„¤ëª…ë“¤
    def _build_tool_descriptions(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´ì˜ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.tools:
            return ""

        tool_list = []
        for tool in self.tools.values():
            tool_info = {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.parameters
            }
            tool_list.append(tool_info)

        tools_text = "\n\n[Available Tools]\n"
        tools_text += json.dumps(tool_list, indent=2, ensure_ascii=False)
        tools_text += "\n\n[Tool Usage Rules]\n"
        tools_text += "1. ONLY use the 'retrieval' tool when you find domain-specific or technical terms in the PROVIDED TRANSCRIPT that are ambiguous.\n"
        tools_text += "2. NEVER search for terms that are NOT in the transcript.\n"
        tools_text += "3. NEVER search for common words or dates (like 'due_date', 'current_date', etc.).\n"
        tools_text += "4. Extract terms directly from the transcript text ONLY.\n"
        tools_text += "5. If no ambiguous domain terms exist in the transcript, do NOT use the tool.\n\n"
        tools_text += "[Tool Usage Format]\n"
        tools_text += 'To use a tool, respond with JSON in this format:\n'
        tools_text += '{"tool": "tool_name", "parameters": {...}}\n'
        tools_text += "After receiving tool results, provide your final answer.\n"

        return tools_text

    def _clean_text(self, text: str) -> str:
        """ì„œë¡œê²Œì´íŠ¸ ë¬¸ì ë° ë¬¸ì œê°€ ë˜ëŠ” ìœ ë‹ˆì½”ë“œ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤."""
        if not isinstance(text, str):
            text = str(text)

        # ì„œë¡œê²Œì´íŠ¸ ë¬¸ì ì œê±°
        try:
            # UTF-8ë¡œ ì¸ì½”ë”© ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³ , ë¶ˆê°€ëŠ¥í•œ ë¬¸ì ì œê±°
            text = text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')
        except Exception:
            # í´ë°±: ì•ˆì „í•œ ë¬¸ìë§Œ ìœ ì§€
            text = ''.join(char for char in text if ord(char) < 0x10000)

        return text

    def _format_messages(self) -> List[Dict[str, str]]:
        """ë©”ì‹œì§€ë¥¼ Qwen ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        formatted = []

        # íˆ´ ì„¤ëª…ê³¼ í•¨ê»˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        system_content = self._clean_text(self.system_prompt)

        if self.tools:
            system_content += "\n" + self._clean_text(self._build_tool_descriptions())

        formatted.append({
            "role": "system",
            "content": system_content
        })

        # ëª¨ë“  ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ì „ë¬¸ì„ ë³¼ ìˆ˜ ìˆë„ë¡)
        for msg in self.messages:
            formatted.append({
                "role": msg.role,
                "content": self._clean_text(msg.content)
            })

        return formatted

    # í˜¸ì¶œëœ íˆ´ ì‹¤í–‰ì‹œí‚¤ê¸°
    def _execute_tool(self, tool_name: str, parameters: Dict[str, Any]) -> str:
        """íˆ´ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if tool_name not in self.tools:
            return f"Error: Tool '{tool_name}' not found"

        try:
            tool = self.tools[tool_name]
            result = tool.function(**parameters)
            return str(result)
        except Exception as e:
            return f"Error executing tool: {str(e)}"

    # ëª¨ë¸ ì‘ë‹µì—ì„œ íˆ´ í˜¸ì¶œ íŒŒì‹±
    def _parse_tool_call(self, text: str) -> Optional[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ì—ì„œ JSON íˆ´ í˜¸ì¶œì„ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            start_idx = text.find('{')
            end_idx = text.rfind('}')

            if start_idx == -1 or end_idx == -1:
                return None

            json_str = text[start_idx:end_idx + 1]
            tool_call = json.loads(json_str)

            if "tool" in tool_call and "parameters" in tool_call:
                return tool_call

            return None
        except json.JSONDecodeError:
            return None

    # ì±„íŒ…
    def chat(
        self,
        user_input: str,
        max_new_tokens: int = 2048,
        temperature: float = 0.7,
        top_p: float = 0.9,
        use_tools: bool = True
    ) -> str:
        """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        if user_input is not None and not isinstance(user_input, str):
            user_input = json.dumps(user_input, ensure_ascii=False)
            print(type(user_input))

        # ë¹ˆ ì…ë ¥ì´ ì•„ë‹ ë•Œë§Œ ë©”ì‹œì§€ ì¶”ê°€ (íˆ´ í˜¸ì¶œ í›„ ì¬ê·€ì—ì„œëŠ” ë¹ˆ ë¬¸ìì—´)
        if user_input:
            self.messages.append(Message(role="user", content=user_input))

        formatted_messages = self._format_messages()

        # í…œí”Œë¦¿ ì‚½ì… ë° í† í°í™”
        model_inputs = self.tokenizer.apply_chat_template(
            formatted_messages,
            tokenize=True,
            add_generation_prompt=True,
            return_tensors="pt"
        )
        
        # apply_chat_templateê°€ tensorë§Œ ì£¼ëŠ” ë²„ì „ ëŒ€ë¹„
        if isinstance(model_inputs, torch.Tensor):
            model_inputs = {"input_ids": model_inputs}

        model_inputs = {k: v.to(self.model.device) for k, v in model_inputs.items()}
        print(type(model_inputs))


        # ì‘ë‹µ ìƒì„±
        with torch.no_grad():
            generated_ids = self.model.generate(
                **model_inputs,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                do_sample=temperature > 0
            )

        # ìƒì„±ëœ ì‘ë‹µ ì¶”ì¶œ
        output_ids = generated_ids[0][len(model_inputs["input_ids"][0]):].tolist()

        # ì‘ë‹µ ë””ì½”ë”©
        content = self.tokenizer.decode(
            output_ids,
            skip_special_tokens=True
        ).strip("\n")

        # íˆ´ í˜¸ì¶œ (use_tools=Trueì¼ ë•Œë§Œ)
        tool_call = self._parse_tool_call(content) if use_tools else None

        if tool_call and self.tools and use_tools:
            # íˆ´ ì‹¤í–‰ì‹œí‚¤ê¸°
            tool_name = tool_call["tool"]
            parameters = tool_call["parameters"]

            print(f"\n[Tool Call: {tool_name}]")
            print(f"Parameters: {parameters}")

            tool_result = self._execute_tool(tool_name, parameters)
            print(f"Result: {tool_result}\n")

            # íˆ´ í˜¸ì¶œ ê²°ê³¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥
            self.messages.append(Message(
                role="assistant",
                content=content,
                tool_calls=[tool_call]
            ))

            self.messages.append(Message(
                role="user",
                content=f"Tool '{tool_name}' returned: {tool_result}\n\nBased on this result, please provide your final answer."
            ))

            # ì‘ë‹µ ì¬ìƒì„±í•˜ê¸°
            return self.chat(
                "",  # ë¹ˆ ë¬¸ìì—´ - ì´ë¯¸ ë©”ì‹œì§€ ì¶”ê°€ë¨
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                use_tools=use_tools
            )

        # íˆìŠ¤í† ë¦¬ì— ì‘ë‹µ ì €ì¥
        self.messages.append(Message(role="assistant", content=content))

        return content

    def clear_history(self):
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.messages = []
        print("Chat history cleared")

    def get_history(self) -> List[Dict[str, str]]:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return [
            {"role": msg.role, "content": msg.content}
            for msg in self.messages
        ]


# ===== Retrieval Tool ìƒì„± í•¨ìˆ˜ =====
def create_retrieval_tool(db_path: str = DB_PATH, domain_filter: Optional[str] = None):
    """FAISS DBë¥¼ ë¡œë“œí•˜ê³  ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(
        model_name="dragonkue/snowflake-arctic-embed-l-v2.0-ko",
        encode_kwargs={'normalize_embeddings': True}
    )

    # FAISS DB ë¡œë“œ
    vector_store = FAISS.load_local(
        db_path,
        embedding_model,
        allow_dangerous_deserialization=True
    )

    if domain_filter:
        print(f"ğŸ”µ FAISS DB ë¡œë“œ ì™„ë£Œ: {db_path} (ë„ë©”ì¸ í•„í„°: {domain_filter})\n")
    else:
        print(f"ğŸ”µ FAISS DB ë¡œë“œ ì™„ë£Œ: {db_path}\n")

    def retrieval_search(term_list: List[str], k: int = 3, domain: Optional[str] = None) -> Dict[str, List[str]]:
        """
        ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ê° ë‹¨ì–´ì˜ ì •ì˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        Args:
            term_list: ê²€ìƒ‰í•  ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ë¦¬ìŠ¤íŠ¸
            k: ê° ìš©ì–´ë‹¹ ê²€ìƒ‰í•  ê²°ê³¼ ê°œìˆ˜
            domain: ê²€ìƒ‰í•  ë„ë©”ì¸ í•„í„° (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ domain_filter ì‚¬ìš©)

        Returns:
            {term: [definition1, definition2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        results = {}

        # ë„ë©”ì¸ í•„í„° ê²°ì • (íŒŒë¼ë¯¸í„° > ìƒì„± ì‹œ í•„í„° > None)
        filter_domain = domain or domain_filter

        for term in term_list:
            # ë„ë©”ì¸ í•„í„°ê°€ ìˆìœ¼ë©´ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì ìš©
            if filter_domain:
                # FAISS ê²€ìƒ‰ ìˆ˜í–‰ (ë©”íƒ€ë°ì´í„° í•„í„°ë§)
                docs = vector_store.similarity_search(
                    term,
                    k=k,
                    filter={"domain": filter_domain}
                )
                # kê°œë§Œ ì„ íƒ
                docs = docs[:k]
            else:
                # í•„í„° ì—†ì´ ê²€ìƒ‰
                docs = []

            definitions = [doc.page_content for doc in docs]
            results[term] = definitions

            # ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸
            if filter_domain:
                print(f"  ğŸ” '{term}' ê²€ìƒ‰ (ë„ë©”ì¸: {filter_domain}) - {len(definitions)}ê°œ ê²°ê³¼")
            else:
                print(f"  ğŸ” ë„ë©”ì¸ ë¯¸ê²€ìƒ‰")

        return results

    return retrieval_search


# ===== íšŒì˜ë¡ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ =====
def process_meeting_transcript(
    transcript: str,
    agent: QwenLLMAgent,
    current_date: str = None,
    use_retrieval: bool = True,
    domain: Optional[str] = None
) -> Dict[str, Any]:

    # í˜„ì¬ ë‚ ì§œ ì„¤ì •
    if current_date is None:
        current_date = datetime.now().strftime("%Y-%m-%d")
        print("ì˜¤ëŠ˜ ë‚ ì§œ !!!!!!: ", current_date)

    # Step 0: ì „ë¬¸ ì´í•´ (Retrieval Tool ì‚¬ìš©)
    if use_retrieval and agent.tools:
        print("=" * 50)
        print("STEP 0: ì „ë¬¸ ì´í•´ ì¤‘ (ë„ë©”ì¸ ìš©ì–´ ê²€ìƒ‰)...")
        print("=" * 50)

        understanding_prompt = f"""ë‹¤ìŒ íšŒì˜ë¡ ì „ë¬¸ì„ ì½ê³ , ì˜ë¯¸ê°€ ëª¨í˜¸í•œ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ë‚˜ ê¸°ìˆ  ìš©ì–´ê°€ ìˆë‹¤ë©´ retrieval toolì„ ì‚¬ìš©í•´ ê²€ìƒ‰í•˜ì„¸ìš”.

[íšŒì˜ë¡ ì „ë¬¸]
{transcript}

ì „ë¬¸ì— ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰í•˜ê³ , ì—†ìœ¼ë©´ "ì´í•´ ì™„ë£Œ"ë¼ê³  ë‹µí•˜ì„¸ìš”."""

        agent.clear_history()
        understanding_response = agent.chat(understanding_prompt, temperature=0.3, use_tools=True)
        print(f"\nì „ë¬¸ ì´í•´ ê²°ê³¼: {understanding_response}\n")

    # Step 1: ì•ˆê±´ ì¶”ì¶œ
    print("=" * 50)
    print("STEP 1: ì•ˆê±´ ì¶”ì¶œ ì¤‘...")
    print("=" * 50)

    summarizer_prompt = PROMPTS["summarizer"].format(transcript=transcript)
    agent.clear_history()
    agendas_response = agent.chat(summarizer_prompt, temperature=0.2, use_tools=False)

    try:
        agendas = json.loads(agendas_response)
    except json.JSONDecodeError:
        print("âš ï¸ ì•ˆê±´ ì¶”ì¶œ JSON íŒŒì‹± ì‹¤íŒ¨")
        agendas = {"agendas": []}

    print(f"\nâœ… ì•ˆê±´ ì¶”ì¶œ ì™„ë£Œ: {len(agendas.get('agendas', []))}ê°œ\n")

    # Step 2: íƒœìŠ¤í¬ ì¶”ì¶œ
    print("=" * 50)
    print("STEP 2: íƒœìŠ¤í¬ ì¶”ì¶œ ì¤‘...")
    print("=" * 50)

    # í˜„ì¬ ë‚ ì§œë¡œë¶€í„° ìš”ì¼ ê³„ì‚°
    date_obj = datetime.strptime(current_date, "%Y-%m-%d")
    weekdays = ["ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼", "ì¼ìš”ì¼"]
    current_weekday = weekdays[date_obj.weekday()]

    task_prompt = PROMPTS["task_extractor"].format(
        current_date=current_date,
        current_weekday=current_weekday,
        transcript=transcript
    )
    agent.clear_history()
    tasks_response = agent.chat(task_prompt, temperature=0.2, use_tools=False)

    try:
        tasks = json.loads(tasks_response)
    except json.JSONDecodeError:
        print("âš ï¸ íƒœìŠ¤í¬ ì¶”ì¶œ JSON íŒŒì‹± ì‹¤íŒ¨")
        tasks = {"tasks": []}

    print(f"\nâœ… íƒœìŠ¤í¬ ì¶”ì¶œ ì™„ë£Œ: {len(tasks.get('tasks', []))}ê°œ\n")

    # ê²°ê³¼ í•©ì¹˜ê¸°
    result = {
        "agendas": agendas.get("agendas", []),
        "tasks": tasks.get("tasks", [])
    }

    return result


def agent_main(domain_input, transcript):

    # Agent ì´ˆê¸°í™”
    print("=" * 50)
    print("QwenLLMAgent ì´ˆê¸°í™” ì¤‘...")
    print("=" * 50)

    agent = QwenLLMAgent(
        model_id=BASE_MODEL_NAME,
        adapter_id=FT_MODEL_NAME
    )

    # ë„ë©”ì¸ ì…ë ¥
    domain_filter = domain_input if domain_input else None

    # Retrieval Tool ë“±ë¡
    print("\n" + "=" * 50)
    print("Retrieval Tool ë“±ë¡ ì¤‘...")
    print("=" * 50)

    retrieval_func = create_retrieval_tool(DB_PATH, domain_filter=domain_filter)
    agent.register_tool(
        name="retrieval",
        description="íšŒì˜ë¡ ì „ë¬¸ì—ì„œ ì˜ë¯¸ê°€ ëª¨í˜¸í•œ ë„ë©”ì¸ íŠ¹í™” ë‹¨ì–´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.",
        parameters={
            "type": "object",
            "properties": {
                "term_list": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "ê²€ìƒ‰í•  ë„ë©”ì¸ ìš©ì–´ ë¦¬ìŠ¤íŠ¸"
                },
                "k": {
                    "type": "integer",
                    "description": "ê° ìš©ì–´ë‹¹ ê²€ìƒ‰í•  ê²°ê³¼ ê°œìˆ˜",
                    "default": 1
                },
                "domain": {
                    "type": "string",
                    "description": "ê²€ìƒ‰í•  ë„ë©”ì¸ (ì˜ˆ: IT, ì˜ë£Œ, ë²•ë¥ )",
                    "default": domain_filter
                }
            },
            "required": ["term_list"]
        },
        function=retrieval_func
    )

    print("\n" + "=" * 50)
    print("íšŒì˜ë¡ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 50)
    result = process_meeting_transcript(
        transcript=transcript,
        agent=agent,
        current_date=None,
        use_retrieval=True,  # ì „ë¬¸ ì´í•´ ì‹œ retrieval tool ì‚¬ìš©
        domain=domain_filter
    )
    return result



if __name__ == "__main__":
    # == ì†Œìš” ì‹œê°„ ì¸¡ì • ë° ì „ë¬¸ ê¸¸ì´ ê´€ë ¨ ==
    import time
    import re
    
    def _basic_text_stats(text: str) -> dict:
        text = "" if text is None else str(text)
        return {
            "transcript_char_len": len(text),
            "transcript_line_count": text.count("\n") + (1 if text else 0),
            "transcript_word_count": len(re.findall(r"\S+", text)),
        }
    # ====================================

    domain_input = input("\nê²€ìƒ‰í•  ë„ë©”ì¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: IT, ì˜ë£Œ, ë²•ë¥ , ì—”í„°ì—†ì´ ì…ë ¥ ì‹œ ì „ì²´ ê²€ìƒ‰): ").strip()

    # íšŒì˜ë¡ ìƒ˜í”Œ
    sample_transcript = input("\níšŒì˜ë¡ ì „ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:\n")
    raw_transcript = sample_transcript
    t0 = time.perf_counter()    # ì‹œê°„ ì¸¡ì • ì‹œì‘
    sample_transcript = preprocess_transcript(sample_transcript)
    result = agent_main(domain_input, sample_transcript)
    t1 = time.perf_counter()    # ì‹œê°„ ì¸¡ì • ì¢…ë£Œ

    meta = {
        "total_sec_from_paste": round(t1 - t0, 3),
        "raw": _basic_text_stats(raw_transcript),
        "preprocessed": _basic_text_stats(sample_transcript)
    }

    print("\n" + "=" * 50)
    print("ìµœì¢… ê²°ê³¼ + ë©”íƒ€(ì‹œê°„/ê¸¸ì´):")
    print("=" * 50)
    print(json.dumps({"meta": meta, "result":result}, ensure_ascii=False, indent=2))