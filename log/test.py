import os, sys
import json
# ì ˆëŒ€ ê²½ë¡œ ì§€ì • 
CURRENT_DIR = os.path.dirname(__file__)
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, "..", ".."))
sys.path.append(PROJECT_ROOT)

from final_runpod_server.sllm_model import build_agent, process_transcript_with_chunks
from final_runpod_server.main_model import load_model_q, load_faiss_db, escape_curly
from gptscore.log.gptscore_utils import Sample, compute_gptscore_for_sample
from gptscore.log.judge_score_utils import Sample as JudgeSample, compute_judge_score_for_sample


db_path = '/workspace/final_runpod_server/faiss_db_merged/'
vector_store, embedding_model = load_faiss_db(db_path)


# ===== ë©”ì¸ ì‹¤í–‰ë¶€ =====
if __name__ == "__main__":
    user_domain = input("ë„ë©”ì¸ ì…ë ¥ (accounting, design, marketing_economy, it): ").strip()
    if user_domain.upper() == "ALL" or user_domain == "" :
        domain_filter = None
    else:
        domain_filter = user_domain

    # ëª¨ë¸ ì—°ê²° (1.5b íŒŒíŠœ ê¸°ë³¸ê°’ ì„¤ì •ë¨)
    model = load_model_q()
    agent = build_agent(model=model, vector_store=vector_store, domain=domain_filter)

    while True:
        print("\n" + "="*60)
        print("íšŒì˜ë¡ ì „ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")
        print("- ê¸´ ì „ë¬¸ì€ ìë™ìœ¼ë¡œ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤")
        print("- ì „ì²´ ì „ë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì•ˆê±´/ìš”ì•½/íƒœìŠ¤í¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
        print("- ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥")
        print("="*60 + "\n")

        query = input("ì „ë¬¸: ")
        if query.lower() in ["exit", "quit"]:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ì²­í¬ ì²˜ë¦¬ ë° ì „ì²´ ìš”ì•½/íƒœìŠ¤í¬ ì¶”ì¶œ
        result = process_transcript_with_chunks(agent=agent, transcript=query, max_chunk_tokens=1500)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ìµœì¢… ê²°ê³¼")
        print("="*60 + "\n")

        if result["chunk_results"]:
            print(f"âœ… {len(result['chunk_results'])}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ\n")

        print("ğŸ“ ì•ˆê±´/ìš”ì•½:")
        print("-" * 60)
        if isinstance(result["full_summary"], dict) and "error" in result["full_summary"]:
            print(f"âŒ ì—ëŸ¬: {result['full_summary']['error']}")
        else:
            print(result["full_summary"])

        print("\nğŸ“‹ íƒœìŠ¤í¬:")
        print("-" * 60)
        if isinstance(result["full_tasks"], dict) and "error" in result["full_tasks"]:
            print(f"âŒ ì—ëŸ¬: {result['full_tasks']['error']}")
        else:
            print(result["full_tasks"])

        print("\n" + "="*60 + "\n")

        # JSON í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥ (ìµœì¢… ê²°ê³¼)
        try:
            result_json = json.dumps(result, ensure_ascii=False, indent=2)
            print("\n JSON ê²°ê³¼ :")
            print(result_json)
        except:
            pass

        # ========================
        default_user_request = (
            "ì´ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½, ì´ìŠˆ, í›„ì† íƒœìŠ¤í¬ë¥¼ í•œêµ­ì–´ë¡œ ì •ë¦¬í•˜ë¼."
        )

        # full_summary / full_tasksë¥¼ ë¬¸ìì—´ë¡œ ì •ê·œí™”
        if isinstance(result["full_summary"], dict):
            summary_text = json.dumps(result["full_summary"], ensure_ascii = False, indent = 2)
        else:
            summary_text = str(result["full_summary"])

        if isinstance(result["full_tasks"], dict):
            tasks_text = json.dumps(result["full_tasks"], ensure_ascii=False, indent =2)
        else:
            tasks_text = str(result["full_tasks"])

        answer_text = (
            " [Summary] \n"
            + summary_text
            + "\n\n [Tasks] \n"
            + tasks_text
        )

        sample = Sample(
            transcript=query,
            user_request = default_user_request,
            answer = answer_text,
        )

        aspects = ["faithfulness", "instruction_following", "structure_clarity"]
        print("\nGPTScore í‰ê°€ ê²°ê³¼:")
        for aspect in aspects:
            score = compute_gptscore_for_sample(sample, aspect)
            print(f"  - {aspect}: {score}")

        # =========================

        # ---------- LLM-as-a-judge (gpt-4o-mini) ----------
        judge_sample = JudgeSample(
            transcript=query,
            user_request=default_user_request,
            answer=answer_text,
        )

        # True â†’ reasoning í¬í•¨, False â†’ ì ìˆ˜ë§Œ (ë¹„ìš© ì ˆì•½)
        with_reasoning = True

        print("\nLLM-as-a-judge (gpt-4o-mini) í‰ê°€ ê²°ê³¼ (1~5 ì ìˆ˜ + ì´ìœ ):")
        for aspect in aspects:
            score, reasoning = compute_judge_score_for_sample(
                judge_sample,
                aspect,
                with_reasoning=with_reasoning,
                return_reasoning=True,   # â† ì—¬ê¸° ì¶”ê°€
            )
            print(f"[{aspect}] ì ìˆ˜: {score}")
            print("[ì´ìœ ]")
            print(reasoning)
            print("-" * 60)

