import os, sys
# ì ˆëŒ€ ê²½ë¡œ ì§€ì • 
CURRENT_DIR = os.path.dirname(__file__)
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, "..", ".."))
sys.path.append(PROJECT_ROOT)

from final_runpod_server.sllm_model import build_agent, process_transcript_with_chunks
from final_runpod_server.main_model import load_model_q, load_faiss_db, escape_curly
from gptscore.log.gptscore_utils import Sample, compute_gptscore_for_sample

db_path = '/workspace/final_runpod_server/faiss_db_merged/'
vector_store, embedding_model = load_faiss_db(db_path)


# ===== ë©”ì¸ ì‹¤í–‰ë¶€ =====
if __name__ == "__main__":
    user_domain = input("ë„ë©”ì¸ ì…ë ¥ (accounting, design, marketing_economy, it): ").strip()
    if user_domain.upper() == "ALL" or user_domain == "" :
        domain_filter = None
    else:
        domain_filter = user_domain

    # ëª¨ë¸ ì—°ê²° (1.5b íŒŒíŠœ ê¸°ë³¸ê°’ ì„¤ì •ë¨)
    model = load_model_q()
    agent = build_agent(model=model, vector_store=vector_store, domain=domain_filter)

    while True:
        print("\n" + "="*60)
        print("íšŒì˜ë¡ ì „ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")
        print("- ê¸´ ì „ë¬¸ì€ ìë™ìœ¼ë¡œ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤")
        print("- ì „ì²´ ì „ë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì•ˆê±´/ìš”ì•½/íƒœìŠ¤í¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
        print("- ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥")
        print("="*60 + "\n")

        query = input("ì „ë¬¸: ")
        if query.lower() in ["exit", "quit"]:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ì²­í¬ ì²˜ë¦¬ ë° ì „ì²´ ìš”ì•½/íƒœìŠ¤í¬ ì¶”ì¶œ
        result = process_transcript_with_chunks(agent=agent, transcript=query, max_chunk_tokens=1500)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ìµœì¢… ê²°ê³¼")
        print("="*60 + "\n")

        if result["chunk_results"]:
            print(f"âœ… {len(result['chunk_results'])}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ\n")

        print("ğŸ“ ì•ˆê±´/ìš”ì•½:")
        print("-" * 60)
        if isinstance(result["full_summary"], dict) and "error" in result["full_summary"]:
            print(f"âŒ ì—ëŸ¬: {result['full_summary']['error']}")
        else:
            print(result["full_summary"])

        print("\nğŸ“‹ íƒœìŠ¤í¬:")
        print("-" * 60)
        if isinstance(result["full_tasks"], dict) and "error" in result["full_tasks"]:
            print(f"âŒ ì—ëŸ¬: {result['full_tasks']['error']}")
        else:
            print(result["full_tasks"])

        print("\n" + "="*60 + "\n")

        # JSON í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥ (ìµœì¢… ê²°ê³¼)
        try:
            result_json = json.dumps(result, ensure_ascii=False, indent=2)
            print("\n JSON ê²°ê³¼ :")
            print(result_json)
        except:
            pass

        # ========================
        default_user_request = (
            "ì´ íšŒì˜ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½, ì´ìŠˆ, í›„ì† íƒœìŠ¤í¬ë¥¼ í•œêµ­ì–´ë¡œ ì •ë¦¬í•˜ë¼."
        )

        sample = Sample(
            transcript=query,
            user_request = default_user_request,
            answer = result,
        )

        aspects = ["faithfulness", "instruction_following", "structure_clarity"]
        print("\nGPTScore í‰ê°€ ê²°ê³¼:")
        for aspect in aspects:
            score = compute_gptscore_for_sample(sample, aspect)
            print(f"  - {aspect}: {score}")